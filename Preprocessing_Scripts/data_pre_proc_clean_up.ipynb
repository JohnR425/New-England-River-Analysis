{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase 1: Use Gage Locations to create a long/lat CSV for PRISM and data table for GIS inorder to create a point shapefile of all the gages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the gage data\n",
    "CT_site = pd.read_csv(\"North_East_Gage_Sites/Connecticut_Gage_Sites/NWISMapperExport.csv\")\n",
    "ME_site = pd.read_csv(\"North_East_Gage_Sites/Maine_Gage_Sites/NWISMapperExport.csv\")\n",
    "MA_site = pd.read_csv(\"North_East_Gage_Sites/Massachusetts_Gage_Sites/NWISMapperExport.csv\")\n",
    "NH_site = pd.read_csv(\"North_East_Gage_Sites/New_Hampshire_Gage_Sites/NWISMapperExport.csv\")\n",
    "RH_site = pd.read_csv(\"North_East_Gage_Sites/Rhode_Island_Gage_Sites/NWISMapperExport.csv\")\n",
    "VT_site = pd.read_csv(\"North_East_Gage_Sites/Vermont_Gage_Sites/NWISMapperExport.csv\")\n",
    "\n",
    "#merge data\n",
    "North_East_site = pd.concat([CT_site,ME_site,MA_site,NH_site,RH_site,VT_site], axis=0, ignore_index=True)\n",
    "#modify and drop unneeded columns (URL column)\n",
    "North_East_site = North_East_site.drop(\" SiteNWISURL\", axis=1)\n",
    "#long-lat data\n",
    "North_East_lonlat = North_East_site[[\" SiteLongitude\", \" SiteLatitude\", \" SiteName\"]]\n",
    "#switch to lat-long\n",
    "North_East_lonlat = North_East_lonlat[[\" SiteLatitude\",\" SiteLongitude\", \" SiteName\"]]\n",
    "#rename columns\n",
    "North_East_lonlat = North_East_lonlat.rename(columns={\" SiteLatitude\": \"Latitude\", \" SiteLongitude\": \"Longitude\", \" SiteName\": \"SiteName\"})\n",
    "#remove duplicates\n",
    "North_East_lonlat = North_East_lonlat.drop_duplicates(ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export long lat points into a csv for PRISM\n",
    "North_East_lonlat.to_csv(\"data/USGS_Gage_Locations.csv\",header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export csv for GIS\n",
    "North_East_site.to_csv(\"data/USGS_Gage_Points.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase 2: Merge time series data from PRISM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read all the PRISM data\n",
    "prism_2010 = pd.read_csv(\"data/PRISM_Time_Series_Data/2010_PRISM_ppt_tmean_stable_4km_20100101_20101231.csv\", skiprows=10)\n",
    "prism_2011 = pd.read_csv(\"data/PRISM_Time_Series_Data/2011_PRISM_ppt_tmean_stable_4km_20110101_20111231.csv\", skiprows=10)\n",
    "prism_2012 = pd.read_csv(\"data/PRISM_Time_Series_Data/2012_PRISM_ppt_tmean_stable_4km_20120101_20121231.csv\", skiprows=10)\n",
    "prism_2013 = pd.read_csv(\"data/PRISM_Time_Series_Data/2013_PRISM_ppt_tmean_stable_4km_20130101_20131231.csv\", skiprows=10)\n",
    "prism_2014 = pd.read_csv(\"data/PRISM_Time_Series_Data/2014_PRISM_ppt_tmean_stable_4km_20140101_20141231.csv\", skiprows=10)\n",
    "prism_2015 = pd.read_csv(\"data/PRISM_Time_Series_Data/2015_PRISM_ppt_tmean_stable_4km_20150101_20151231.csv\", skiprows=10)\n",
    "prism_2016 = pd.read_csv(\"data/PRISM_Time_Series_Data/2016_PRISM_ppt_tmean_stable_4km_20160101_20161231.csv\", skiprows=10)\n",
    "prism_2017 = pd.read_csv(\"data/PRISM_Time_Series_Data/2017_PRISM_ppt_tmean_stable_4km_20170101_20171231.csv\", skiprows=10)\n",
    "prism_2018 = pd.read_csv(\"data/PRISM_Time_Series_Data/2018_PRISM_ppt_tmean_stable_4km_20180101_20181231.csv\", skiprows=10)\n",
    "prism_2019 = pd.read_csv(\"data/PRISM_Time_Series_Data/2019_PRISM_ppt_tmean_stable_4km_20190101_20191231.csv\", skiprows=10)\n",
    "prism_2020 = pd.read_csv(\"data/PRISM_Time_Series_Data/2020_PRISM_ppt_tmean_stable_4km_20200101_20201231.csv\", skiprows=10)\n",
    "prism_2021 = pd.read_csv(\"data/PRISM_Time_Series_Data/2021_PRISM_ppt_tmean_stable_4km_20210101_20211231.csv\", skiprows=10)\n",
    "prism_2022 = pd.read_csv(\"data/PRISM_Time_Series_Data/2022_PRISM_ppt_tmean_stable_4km_20220101_20221231.csv\", skiprows=10)\n",
    "prism_2023 = pd.read_csv(\"data/PRISM_Time_Series_Data/2023_PRISM_ppt_tmean_provisional_4km_20230101_20231231.csv\", skiprows=10)\n",
    "#combine all the PRISM data\n",
    "prism_data = pd.concat([prism_2010,prism_2011,prism_2012,prism_2013,prism_2014,\n",
    "                        prism_2015,prism_2016,prism_2017,prism_2018,prism_2019,\n",
    "                        prism_2020, prism_2021, prism_2022, prism_2023], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Elevation (ft)</th>\n",
       "      <th>Date</th>\n",
       "      <th>ppt (inches)</th>\n",
       "      <th>tmean (degrees F)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PENDLETON HI</td>\n",
       "      <td>-71.8342</td>\n",
       "      <td>41.4748</td>\n",
       "      <td>161</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>0.24</td>\n",
       "      <td>29.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PENDLETON HI</td>\n",
       "      <td>-71.8342</td>\n",
       "      <td>41.4748</td>\n",
       "      <td>161</td>\n",
       "      <td>2010-01-02</td>\n",
       "      <td>0.08</td>\n",
       "      <td>32.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PENDLETON HI</td>\n",
       "      <td>-71.8342</td>\n",
       "      <td>41.4748</td>\n",
       "      <td>161</td>\n",
       "      <td>2010-01-03</td>\n",
       "      <td>0.08</td>\n",
       "      <td>23.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PENDLETON HI</td>\n",
       "      <td>-71.8342</td>\n",
       "      <td>41.4748</td>\n",
       "      <td>161</td>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PENDLETON HI</td>\n",
       "      <td>-71.8342</td>\n",
       "      <td>41.4748</td>\n",
       "      <td>161</td>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175560</th>\n",
       "      <td>Elizabeth Mi</td>\n",
       "      <td>-72.3242</td>\n",
       "      <td>43.8243</td>\n",
       "      <td>1099</td>\n",
       "      <td>2010-12-27</td>\n",
       "      <td>0.46</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175561</th>\n",
       "      <td>Elizabeth Mi</td>\n",
       "      <td>-72.3242</td>\n",
       "      <td>43.8243</td>\n",
       "      <td>1099</td>\n",
       "      <td>2010-12-28</td>\n",
       "      <td>0.05</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175562</th>\n",
       "      <td>Elizabeth Mi</td>\n",
       "      <td>-72.3242</td>\n",
       "      <td>43.8243</td>\n",
       "      <td>1099</td>\n",
       "      <td>2010-12-29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175563</th>\n",
       "      <td>Elizabeth Mi</td>\n",
       "      <td>-72.3242</td>\n",
       "      <td>43.8243</td>\n",
       "      <td>1099</td>\n",
       "      <td>2010-12-30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175564</th>\n",
       "      <td>Elizabeth Mi</td>\n",
       "      <td>-72.3242</td>\n",
       "      <td>43.8243</td>\n",
       "      <td>1099</td>\n",
       "      <td>2010-12-31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175565 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name  Longitude  Latitude  Elevation (ft)        Date  \\\n",
       "0       PENDLETON HI   -71.8342   41.4748             161  2010-01-01   \n",
       "1       PENDLETON HI   -71.8342   41.4748             161  2010-01-02   \n",
       "2       PENDLETON HI   -71.8342   41.4748             161  2010-01-03   \n",
       "3       PENDLETON HI   -71.8342   41.4748             161  2010-01-04   \n",
       "4       PENDLETON HI   -71.8342   41.4748             161  2010-01-05   \n",
       "...              ...        ...       ...             ...         ...   \n",
       "175560  Elizabeth Mi   -72.3242   43.8243            1099  2010-12-27   \n",
       "175561  Elizabeth Mi   -72.3242   43.8243            1099  2010-12-28   \n",
       "175562  Elizabeth Mi   -72.3242   43.8243            1099  2010-12-29   \n",
       "175563  Elizabeth Mi   -72.3242   43.8243            1099  2010-12-30   \n",
       "175564  Elizabeth Mi   -72.3242   43.8243            1099  2010-12-31   \n",
       "\n",
       "        ppt (inches)  tmean (degrees F)  \n",
       "0               0.24               29.5  \n",
       "1               0.08               32.1  \n",
       "2               0.08               23.4  \n",
       "3               0.04               18.5  \n",
       "4               0.00               25.0  \n",
       "...              ...                ...  \n",
       "175560          0.46               11.9  \n",
       "175561          0.05               11.2  \n",
       "175562          0.00               17.1  \n",
       "175563          0.00               21.0  \n",
       "175564          0.00               25.5  \n",
       "\n",
       "[175565 rows x 7 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prism_2010"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phase 2.1: Add the full site names back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_close_enough(row1, row2, tolerance):\n",
    "    return (abs(row1['Latitude'] - row2['Latitude']) <= tolerance) and (abs(row1['Longitude'] - row2['Longitude']) <= tolerance)\n",
    "\n",
    "tolerance = 0.00006  # Define the tolerance for how close the values need to be\n",
    "merged_data = []\n",
    "\n",
    "for i, row1 in prism_data.iterrows():\n",
    "    for j, row2 in North_East_lonlat.iterrows():\n",
    "        if is_close_enough(row1, row2, tolerance):\n",
    "            merged_row = {**row1, **row2}\n",
    "            merged_data.append(merged_row)\n",
    "\n",
    "df_merged = pd.DataFrame(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export more accurate data\n",
    "prism_data.to_csv(\"data/PRISM_data_unedited\", index=False)\n",
    "df_merged.to_csv(\"data/PRISM_data_edited\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "prism_data_2 = pd.read_csv(\"data/PRISM_data_edited_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2: Remove incorrect rows with SiteName: \"Pittsburg Meteorologic Station near Pittsburg, NH\" Name: \"CONNECTICUT \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pit_bad_data = prism_data_2[(prism_data_2['SiteName'] == \"Pittsburg Meteorologic Station near Pittsburg, NH\") & (prism_data_2['Name']==\"CONNECTICUT \")]\n",
    "prism_data_3 = prism_data_2[(prism_data_2['SiteName'] != \"Pittsburg Meteorologic Station near Pittsburg, NH\") | (prism_data_2['Name']!=\"CONNECTICUT \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism_data_3.to_csv(\"data/PRISM_data_3\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3: Adding Site Code back to the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Site_Codes = pd.read_csv(\"data/USGS_Gage_Points.csv\")\n",
    "Site_Codes = Site_Codes.drop_duplicates()\n",
    "Site_Codes = Site_Codes.iloc[:,0]\n",
    "\n",
    "def add_leading_zeros(series):\n",
    "    return series.apply(lambda x: f'{int(x):08d}')\n",
    "\n",
    "Site_Codes = add_leading_zeros(Site_Codes)\n",
    "Site_Codes.to_csv(\"data/Site_Codes_List\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_zero_conditionally(series):\n",
    "    # Convert each value in the series to a string and prepend a zero if length is less than 15\n",
    "    return series.apply(lambda x: '0' + str(x) if len(str(x)) < 15 else str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SiteNameNCodes = pd.read_csv(\"data/USGS_Gage_Points.csv\")\n",
    "SiteNameNCodes = SiteNameNCodes.drop_duplicates()\n",
    "SiteNameNCodes = SiteNameNCodes.iloc[:,0]\n",
    "\n",
    "SiteNameNCodes = append_zero_conditionally(SiteNameNCodes)\n",
    "\n",
    "# SiteNameNCodes = SiteNameNCodes.rename(columns={' SiteName': \"SiteName\"})\n",
    "SiteNameNCodes.to_csv(\"data/Site_Codes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v3 = pd.read_csv(\"data/PRISM_data_3\")\n",
    "names_and_codes = pd.read_csv(\"data/Site_Codes_And_Names\")\n",
    "data_v4 = pd.merge(data_v3, names_and_codes, on=\"SiteName\", how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v4.to_csv(\"data/PRISM_data_4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v4 = pd.read_csv(\"data/PRISM_data_4.csv\")\n",
    "code_col = data_v4.iloc[:,8]\n",
    "true_code_col = append_zero_conditionally(code_col)\n",
    "data_v4[\"Site Number\"] = true_code_col\n",
    "data_v5 = data_v4.iloc[:,[1,2,3,4,5,6,7,9]]\n",
    "data_v5.to_csv(\"data/PRISM_data_5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4: Make Site Number column a string column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_v5 = pd.read_csv(\"data/Gage_Points_ONLY_DISCHARGE.csv\", dtype={\"Site Number\": str})\n",
    "data_v5['Site Number'] = data_v5['Site Number'].astype(str).str.zfill(3)\n",
    "data_v5['Site Number'] = data_v5['Site Number'].apply(lambda x: f'\"{x}\"')\n",
    "data_v5.to_csv(\"data/Gage_Points_ONLY_DISCHARGE_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.0: Debug tool that helps you find the line of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site holds values between natural numbers 0 to 424 \n",
    "def siteNdate_to_line(site: int, year: int, month: int, day: int):\n",
    "    def is_leap_year(year):\n",
    "        if year == 2012 or year == 2016 or year == 2020:\n",
    "            return True\n",
    "        else:\n",
    "            False\n",
    "    \n",
    "    def days_in_year(year):\n",
    "        if is_leap_year(year):\n",
    "            days_in_year = 366\n",
    "        else:\n",
    "            days_in_year = 365\n",
    "        return days_in_year\n",
    "\n",
    "    def years_to_line(year): \n",
    "        if year == 2010:\n",
    "            return 0\n",
    "        return years_to_line(year-1) + (days_in_year(year-1) * 425)\n",
    "    \n",
    "    def site_to_line(year, site):\n",
    "        return days_in_year(year) * site\n",
    "    \n",
    "    def month_to_line(year, month):\n",
    "        if month == 1:\n",
    "            return 0\n",
    "        if month == 3:\n",
    "            if is_leap_year(year):\n",
    "                leap_day = 1\n",
    "            else:\n",
    "                leap_day = 0\n",
    "            return month_to_line(year, month-1) + 28 + leap_day\n",
    "        if month == 2 or month == 4 or month == 6 or month == 8 or month == 9 or month == 11:\n",
    "            return month_to_line(year, month-1) + 31\n",
    "        else:\n",
    "            return month_to_line(year, month-1) + 30\n",
    "\n",
    "    return years_to_line(year) + site_to_line(year, site) + month_to_line(year, month) + day + 1\n",
    "\n",
    "#Input site and date\n",
    "site_and_date = {\n",
    "    \"Site_Number\": 120,\n",
    "    \"Date\": [2020,12,31]\n",
    "}\n",
    "line = siteNdate_to_line(site_and_date[\"Site_Number\"], site_and_date[\"Date\"][0], site_and_date[\"Date\"][1], site_and_date[\"Date\"][2])\n",
    "site_name = North_East_lonlat.iloc[site_and_date[\"Site_Number\"], 2]\n",
    "print(site_name + \" on \" + str(site_and_date[\"Date\"][0]) + \"-\" + str(site_and_date[\"Date\"][1]) + \"-\" + str(site_and_date[\"Date\"][2]) + \" \" + \"on line \" + str(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.0: Adding Discharge Data from USGS to data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prismv5 = pd.read_csv(\"data/PRISM_data_5.csv\", dtype={\"Site Number\": str})\n",
    "USGS_DIS = pd.read_csv(\"data/USGS_Discharge_Gage_Data.csv\", dtype={\"site_no\": str})\n",
    "USGS_DIS = USGS_DIS.iloc[:,[1,2,3]]\n",
    "USGS_DIS = USGS_DIS.rename(columns={\"X_00060_00003\": \"Mean Discharge (cubic ft/sec)\", \"site_no\": \"Site Number\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gage_Points_ONLY_DISCHARGE = pd.merge(USGS_DIS, prismv5, on=[\"Site Number\", \"Date\"], how=\"left\")\n",
    "Gage_Points_ONLY_DISCHARGE = Gage_Points_ONLY_DISCHARGE.rename(columns={\"SiteName\": \"Site Name\"})\n",
    "new_order = [\"Latitude\", \"Longitude\", \"Date\", \"Elevation (ft)\",\"Mean Discharge (cubic ft/sec)\",\"ppt (inches)\",\"tmean (degrees F)\", \"Site Number\", \"Site Name\"]\n",
    "Gage_Points_ONLY_DISCHARGE = Gage_Points_ONLY_DISCHARGE[new_order]\n",
    "\n",
    "Gage_Points_ALL_DATA = pd.merge(USGS_DIS, prismv5, on=[\"Site Number\", \"Date\"], how=\"outer\")\n",
    "Gage_Points_ALL_DATA = Gage_Points_ALL_DATA.rename(columns={\"SiteName\": \"Site Name\"})\n",
    "Gage_Points_ALL_DATA = Gage_Points_ALL_DATA[new_order]\n",
    "\n",
    "Gage_Points_ONLY_DISCHARGE.to_csv(\"data/Gage_Points_ONLY_DISCHARGE.csv\", index=False)\n",
    "Gage_Points_ALL_DATA.to_csv(\"data/Gage_Points_ALL_DATA.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.0: Find what state each gage is in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Maine', 'Maine', 'Maine', 'Maine', nan, 'Maine', nan, 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', nan, 'Maine', nan, 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'Maine', 'Maine', 'Maine', 'Maine', 'Maine', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'New Hampshire', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'New Hampshire', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', nan, 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Rhode Island', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Rhode Island', 'Connecticut', 'Rhode Island', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Massachusetts', 'Massachusetts', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'New Hampshire', 'Vermont', 'New Hampshire', 'New Hampshire', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'New Hampshire', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'New Hampshire', 'Vermont', 'Vermont', 'New Hampshire', 'New Hampshire', 'Vermont', 'Vermont', 'New Hampshire', 'New Hampshire', 'Vermont', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Connecticut', 'Connecticut', 'Connecticut', 'Massachusetts', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Vermont', 'New York', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Connecticut', 'Maine', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', 'Massachusetts', nan, 'New Hampshire', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'Vermont', 'New Hampshire', 'New Hampshire', 'New Hampshire', 'Vermont', 'Vermont', 'Vermont', 'New Hampshire', 'Vermont', 'New Hampshire', 'Vermont', 'Vermont', 'New Hampshire', 'New Hampshire', 'Rhode Island', nan]\n"
     ]
    }
   ],
   "source": [
    "# Load state boundary data\n",
    "states = gpd.read_file(\"GIS Projects/state_boundries.shp\")  # or .shp\n",
    "\n",
    "# Read the gage CSV file\n",
    "df = pd.read_csv(\"data/Gage_Discharge_Data/gage.csv\", dtype={'Site Number': 'string'})\n",
    "\n",
    "# Convert lat/lon to Point geometry\n",
    "df['geometry'] = df.apply(lambda row: Point(row['Longitude'], row['Latitude']), axis=1)\n",
    "\n",
    "# Convert to a GeoDataFrame\n",
    "gage = gpd.GeoDataFrame(df, geometry='geometry', crs=\"EPSG:4326\")  # WGS 84\n",
    "\n",
    "# Ensure both datasets have the same CRS\n",
    "states = states.to_crs(epsg=4326)\n",
    "\n",
    "# Spatial join to find which state each point falls in\n",
    "points_with_states = gpd.sjoin(gage, states, how=\"left\", predicate=\"within\")\n",
    "\n",
    "# Extract state names\n",
    "state_names = points_with_states[\"shapeName\"].tolist()  # Replace with actual column name in the boundary data\n",
    "\n",
    "print(state_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    Maine\n",
       "Name: shapeName, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "points_with_states[points_with_states[\"Site Number\"] == '01011500'][\"shapeName\"]\n",
    "points_with_states[points_with_states[\"Site Number\"] == '01010070'][\"shapeName\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2: Identify which gages didn't return a state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Elevation (ft)</th>\n",
       "      <th>Site Number</th>\n",
       "      <th>Site Name</th>\n",
       "      <th>geometry</th>\n",
       "      <th>index_right</th>\n",
       "      <th>shapeGroup</th>\n",
       "      <th>shapeType</th>\n",
       "      <th>shapeID</th>\n",
       "      <th>shapeName</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shape_Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.206979</td>\n",
       "      <td>-68.956428</td>\n",
       "      <td>866</td>\n",
       "      <td>01011500</td>\n",
       "      <td>St. Francis River near Connors, New Brunswick</td>\n",
       "      <td>POINT (-68.95643 47.20698)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>47.283333</td>\n",
       "      <td>-68.585278</td>\n",
       "      <td>679</td>\n",
       "      <td>01014000</td>\n",
       "      <td>St. John River below Fish R, nr Fort Kent, Maine</td>\n",
       "      <td>POINT (-68.58528 47.28333)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>45.568333</td>\n",
       "      <td>-67.428333</td>\n",
       "      <td>459</td>\n",
       "      <td>01018500</td>\n",
       "      <td>St. Croix River at Vanceboro, Maine</td>\n",
       "      <td>POINT (-67.42833 45.56833)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>45.136944</td>\n",
       "      <td>-67.318056</td>\n",
       "      <td>128</td>\n",
       "      <td>01021000</td>\n",
       "      <td>St. Croix River at Baring, Maine</td>\n",
       "      <td>POINT (-67.31806 45.13694)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>41.941770</td>\n",
       "      <td>-70.622534</td>\n",
       "      <td>7</td>\n",
       "      <td>01105876</td>\n",
       "      <td>EEL RIVER AT RT 3A NEAR PLYMOUTH, MA</td>\n",
       "      <td>POINT (-70.62253 41.94177)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>42.049722</td>\n",
       "      <td>-70.182222</td>\n",
       "      <td>0</td>\n",
       "      <td>420259070105600</td>\n",
       "      <td>PROVINCETOWN TIDE GAGE, PROVINCETOWN, MA</td>\n",
       "      <td>POINT (-70.18222 42.04972)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>41.572222</td>\n",
       "      <td>-71.445278</td>\n",
       "      <td>56</td>\n",
       "      <td>413413071270400</td>\n",
       "      <td>WICKFORD TIDE GAGE NORTH KINGSTOWN, RI</td>\n",
       "      <td>POINT (-71.44528 41.57222)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Latitude  Longitude  Elevation (ft)      Site Number  \\\n",
       "4    47.206979 -68.956428             866         01011500   \n",
       "6    47.283333 -68.585278             679         01014000   \n",
       "15   45.568333 -67.428333             459         01018500   \n",
       "17   45.136944 -67.318056             128         01021000   \n",
       "158  41.941770 -70.622534               7         01105876   \n",
       "400  42.049722 -70.182222               0  420259070105600   \n",
       "424  41.572222 -71.445278              56  413413071270400   \n",
       "\n",
       "                                            Site Name  \\\n",
       "4       St. Francis River near Connors, New Brunswick   \n",
       "6    St. John River below Fish R, nr Fort Kent, Maine   \n",
       "15                St. Croix River at Vanceboro, Maine   \n",
       "17                   St. Croix River at Baring, Maine   \n",
       "158              EEL RIVER AT RT 3A NEAR PLYMOUTH, MA   \n",
       "400          PROVINCETOWN TIDE GAGE, PROVINCETOWN, MA   \n",
       "424            WICKFORD TIDE GAGE NORTH KINGSTOWN, RI   \n",
       "\n",
       "                       geometry  index_right shapeGroup shapeType shapeID  \\\n",
       "4    POINT (-68.95643 47.20698)          NaN        NaN       NaN     NaN   \n",
       "6    POINT (-68.58528 47.28333)          NaN        NaN       NaN     NaN   \n",
       "15   POINT (-67.42833 45.56833)          NaN        NaN       NaN     NaN   \n",
       "17   POINT (-67.31806 45.13694)          NaN        NaN       NaN     NaN   \n",
       "158  POINT (-70.62253 41.94177)          NaN        NaN       NaN     NaN   \n",
       "400  POINT (-70.18222 42.04972)          NaN        NaN       NaN     NaN   \n",
       "424  POINT (-71.44528 41.57222)          NaN        NaN       NaN     NaN   \n",
       "\n",
       "    shapeName  Shape_Leng  Shape_Area  \n",
       "4         NaN         NaN         NaN  \n",
       "6         NaN         NaN         NaN  \n",
       "15        NaN         NaN         NaN  \n",
       "17        NaN         NaN         NaN  \n",
       "158       NaN         NaN         NaN  \n",
       "400       NaN         NaN         NaN  \n",
       "424       NaN         NaN         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "points_with_states[points_with_states[\"shapeName\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3: Update states of gages manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site Number</th>\n",
       "      <th>shapeName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01010000</td>\n",
       "      <td>Maine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01010070</td>\n",
       "      <td>Maine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01010500</td>\n",
       "      <td>Maine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01011000</td>\n",
       "      <td>Maine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01011500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>444459071375301</td>\n",
       "      <td>Vermont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>444657071074401</td>\n",
       "      <td>New Hampshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>450225071263901</td>\n",
       "      <td>New Hampshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>411838071513000</td>\n",
       "      <td>Rhode Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>413413071270400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Site Number      shapeName\n",
       "0           01010000          Maine\n",
       "1           01010070          Maine\n",
       "2           01010500          Maine\n",
       "3           01011000          Maine\n",
       "4           01011500            NaN\n",
       "..               ...            ...\n",
       "420  444459071375301        Vermont\n",
       "421  444657071074401  New Hampshire\n",
       "422  450225071263901  New Hampshire\n",
       "423  411838071513000   Rhode Island\n",
       "424  413413071270400            NaN\n",
       "\n",
       "[425 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "points_with_states_2 = points_with_states.iloc[:,[3,10]]\n",
    "display(points_with_states_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site Number</th>\n",
       "      <th>shapeName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Site Number, shapeName]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site Number</th>\n",
       "      <th>shapeName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01010000</td>\n",
       "      <td>Maine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01010070</td>\n",
       "      <td>Maine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01010500</td>\n",
       "      <td>Maine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01011000</td>\n",
       "      <td>Maine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01011500</td>\n",
       "      <td>Maine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>444459071375301</td>\n",
       "      <td>Vermont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>444657071074401</td>\n",
       "      <td>New Hampshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>450225071263901</td>\n",
       "      <td>New Hampshire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>411838071513000</td>\n",
       "      <td>Rhode Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>413413071270400</td>\n",
       "      <td>Rhode Island</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Site Number      shapeName\n",
       "0           01010000          Maine\n",
       "1           01010070          Maine\n",
       "2           01010500          Maine\n",
       "3           01011000          Maine\n",
       "4           01011500          Maine\n",
       "..               ...            ...\n",
       "420  444459071375301        Vermont\n",
       "421  444657071074401  New Hampshire\n",
       "422  450225071263901  New Hampshire\n",
       "423  411838071513000   Rhode Island\n",
       "424  413413071270400   Rhode Island\n",
       "\n",
       "[425 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "points_with_states_3 = points_with_states_2.copy()\n",
    "points_with_states_3.loc[points_with_states_3['Site Number'] == \"01011500\", 'shapeName'] = 'Maine'\n",
    "points_with_states_3.loc[points_with_states_3['Site Number'] == \"01014000\", 'shapeName'] = 'Maine'\n",
    "points_with_states_3.loc[points_with_states_3['Site Number'] == \"01018500\", 'shapeName'] = 'Maine'\n",
    "points_with_states_3.loc[points_with_states_3['Site Number'] == \"01021000\", 'shapeName'] = 'Maine'\n",
    "points_with_states_3.loc[points_with_states_3['Site Number'] == \"01105876\", 'shapeName'] = 'Massachusetts'\n",
    "points_with_states_3.loc[points_with_states_3['Site Number'] == \"420259070105600\", 'shapeName'] = 'Massachusetts'\n",
    "points_with_states_3.loc[points_with_states_3['Site Number'] == \"413413071270400\", 'shapeName'] = 'Rhode Island'\n",
    "points_with_states_3.loc[points_with_states_3['Site Number'] == \"04280000\", 'shapeName'] = 'Vermont'\n",
    "display(points_with_states_3[points_with_states_3['shapeName'].isna()])\n",
    "display(points_with_states_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Maine', 'New Hampshire', 'Massachusetts', 'Rhode Island',\n",
       "       'Connecticut', 'Vermont'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ensure all created states returned belong to New England\n",
    "points_with_states_3['shapeName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site Number</th>\n",
       "      <th>State</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Elevation (ft)</th>\n",
       "      <th>Site Name</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01010000</td>\n",
       "      <td>Maine</td>\n",
       "      <td>46.700556</td>\n",
       "      <td>-69.715556</td>\n",
       "      <td>1004</td>\n",
       "      <td>St. John River at Ninemile Bridge, Maine</td>\n",
       "      <td>POINT (-69.7155556 46.70055556)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01010070</td>\n",
       "      <td>Maine</td>\n",
       "      <td>46.893889</td>\n",
       "      <td>-69.751667</td>\n",
       "      <td>1073</td>\n",
       "      <td>Big Black River near Depot Mtn, Maine</td>\n",
       "      <td>POINT (-69.7516667 46.89388889)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01010500</td>\n",
       "      <td>Maine</td>\n",
       "      <td>47.113056</td>\n",
       "      <td>-69.088056</td>\n",
       "      <td>948</td>\n",
       "      <td>St. John River at Dickey, Maine</td>\n",
       "      <td>POINT (-69.0880556 47.11305556)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01011000</td>\n",
       "      <td>Maine</td>\n",
       "      <td>47.069722</td>\n",
       "      <td>-69.079444</td>\n",
       "      <td>840</td>\n",
       "      <td>Allagash River near Allagash, Maine</td>\n",
       "      <td>POINT (-69.0794444 47.0697222)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01011500</td>\n",
       "      <td>Maine</td>\n",
       "      <td>47.206979</td>\n",
       "      <td>-68.956428</td>\n",
       "      <td>866</td>\n",
       "      <td>St. Francis River near Connors, New Brunswick</td>\n",
       "      <td>POINT (-68.9564281 47.20697926)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>444459071375301</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>44.749722</td>\n",
       "      <td>-71.631389</td>\n",
       "      <td>1056</td>\n",
       "      <td>N Stratford Meteorologic Station at N Stratfor...</td>\n",
       "      <td>POINT (-71.63138889 44.7497222)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>444657071074401</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>44.782500</td>\n",
       "      <td>-71.128889</td>\n",
       "      <td>1404</td>\n",
       "      <td>Errol Precipitation at Errol, New Hampshire</td>\n",
       "      <td>POINT (-71.12888889 44.7825)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>450225071263901</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>45.040242</td>\n",
       "      <td>-71.444039</td>\n",
       "      <td>1490</td>\n",
       "      <td>Pittsburg Meteorologic Station near Pittsburg, NH</td>\n",
       "      <td>POINT (-71.44403889 45.04024167)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>411838071513000</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>41.310556</td>\n",
       "      <td>-71.858333</td>\n",
       "      <td>0</td>\n",
       "      <td>WATCH HILL COVE TIDE GAGE WESTERLY, RI</td>\n",
       "      <td>POINT (-71.8583333 41.31055556)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>413413071270400</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>41.572222</td>\n",
       "      <td>-71.445278</td>\n",
       "      <td>56</td>\n",
       "      <td>WICKFORD TIDE GAGE NORTH KINGSTOWN, RI</td>\n",
       "      <td>POINT (-71.44527778 41.5722222)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Site Number          State   Latitude  Longitude  Elevation (ft)  \\\n",
       "0           01010000          Maine  46.700556 -69.715556            1004   \n",
       "1           01010070          Maine  46.893889 -69.751667            1073   \n",
       "2           01010500          Maine  47.113056 -69.088056             948   \n",
       "3           01011000          Maine  47.069722 -69.079444             840   \n",
       "4           01011500          Maine  47.206979 -68.956428             866   \n",
       "..               ...            ...        ...        ...             ...   \n",
       "420  444459071375301        Vermont  44.749722 -71.631389            1056   \n",
       "421  444657071074401  New Hampshire  44.782500 -71.128889            1404   \n",
       "422  450225071263901  New Hampshire  45.040242 -71.444039            1490   \n",
       "423  411838071513000   Rhode Island  41.310556 -71.858333               0   \n",
       "424  413413071270400   Rhode Island  41.572222 -71.445278              56   \n",
       "\n",
       "                                             Site Name  \\\n",
       "0             St. John River at Ninemile Bridge, Maine   \n",
       "1                Big Black River near Depot Mtn, Maine   \n",
       "2                      St. John River at Dickey, Maine   \n",
       "3                  Allagash River near Allagash, Maine   \n",
       "4        St. Francis River near Connors, New Brunswick   \n",
       "..                                                 ...   \n",
       "420  N Stratford Meteorologic Station at N Stratfor...   \n",
       "421        Errol Precipitation at Errol, New Hampshire   \n",
       "422  Pittsburg Meteorologic Station near Pittsburg, NH   \n",
       "423             WATCH HILL COVE TIDE GAGE WESTERLY, RI   \n",
       "424             WICKFORD TIDE GAGE NORTH KINGSTOWN, RI   \n",
       "\n",
       "                             geometry  \n",
       "0     POINT (-69.7155556 46.70055556)  \n",
       "1     POINT (-69.7516667 46.89388889)  \n",
       "2     POINT (-69.0880556 47.11305556)  \n",
       "3      POINT (-69.0794444 47.0697222)  \n",
       "4     POINT (-68.9564281 47.20697926)  \n",
       "..                                ...  \n",
       "420   POINT (-71.63138889 44.7497222)  \n",
       "421      POINT (-71.12888889 44.7825)  \n",
       "422  POINT (-71.44403889 45.04024167)  \n",
       "423   POINT (-71.8583333 41.31055556)  \n",
       "424   POINT (-71.44527778 41.5722222)  \n",
       "\n",
       "[425 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Merge the data from gages with the state values\n",
    "points_with_states_4 = points_with_states_3.merge(df, on=\"Site Number\")\n",
    "points_with_states_4 = points_with_states_4.rename(columns={\"shapeName\": \"State\"})\n",
    "display(points_with_states_4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
